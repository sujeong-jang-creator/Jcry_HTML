
0) 인공지능이란?
: 인간의 지능(인지, 추론, 학습 등)을 컴퓨터나 시스템 등으로 만든 것 또는, 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 기술 또는 과학
규칙, 데이터 학습을 기반으로 하는 기계가 사람의 지능을 모방하게 하는 기술.
존 매카시가 "지능이 있는 기계를 만들기 위한 과학과 공학"이란 논문에서 처음으로 제안(1955년)

  (1) 인공지능의 발전을 가능하게 만든 요소

    - 데이터의 급격한 증가.
      : 디지털 사진, 동영상, IoT(Internet of Things : 사물인터넷), SNS 컨텐츠 등으로 인해 데이터가 폭발적으로 증가

    - 알고리즘의 발전
      : 급증한 데이터를 이용한 기존 알고리즘 개선 및 새로운 알고리즘들이 개발됨.

    - 컴퓨터 하드웨어의 발전
      : CPU와 GPU의 발전

1) 튜링테스트란?
: 1950년대 앨런 튜링(Alan Turing)이 제안한 인공지능 여부를 테스트 하는 방법
테스트 하는 사람이 컴퓨터 화면으로 사람과 기계와 각각 대화를 한 뒤 
어느쪽이 사람인지 기계인지 구분할 수 없으면 인간수준의 사고를 가진것으로 판명하는 방법

2) 머신러닝이란?
: 데이터를 기반으로 패턴을 학습하여 결과를 추론하는 것
요즈음은 데이터와 값만 있으면 인공지능이 스스로 패턴학습이 가능함. 
이 패턴학습이 가능하도록 우리가 하는 것이 머신러닝이다.

  - 머신러닝과 기존 프로그래밍의 차이
    : 전통적 프로그래밍 방식은 컴퓨터에 [데이터와 프로그램(함수, 알고리즘)]을 넣어 결과(output)을 도출함.
      머신러닝은 컴퓨터에 [데이터와 결과(output)]을 넣어 프로그램(알고리즘, 모델, 규칙)을 도출함.

3) 머신러닝 분류

    * 단어정리

      - Feature
        : 예측하거나 분류해야하는 테이터의 특성, 속성 값
          입력 변수(input), 독립변수
          일반적으로 X로 표기

      - Label
        : 예측하거나 분류해야 하는 값
          출력 변수(output), 종속변수
          일반적으로 y로 표기

    (1) 지도학습(Supervised Learning) > prediction(label값)이 있음
    : 예측해야할 값과 데이터를 학습시키는 방식.

        지도학습의 종류

        - 회귀(Regression) : 수치형(numeric value)을 맞추는 것.
          ex) 집 값 예상, 가격 예상, 온도 예상

          의사결정트리(Decision Tree)
          선형 회귀(Linear Regression)
          릿지 회귀(Rige Regression)
          라쏘 회귀(Lasso Regression)
          엘라스틱 넷(Elastic Net)
          K-최근접 이웃(K-Nearest Neighbors, KNN)
          나이브 베이즈(Naive Bayes)
          서포트 벡터 머신(Support Vector Machine, SVM)
          랜덤 포레스트(Random Forest)
          신경망(Neural Network)

        - 분류(Classification) : 분류형(categorical value)을 맞추는 것.
          두개 이상의 클래스(범주)에서 선택을 묻는 지도 학습방법
          ex) 스팸메일, 종류판별(개/고양이), 암진단

          이진 분류 : 분류 대상 클래스가 2개
          다중 분류 : 분류 대상 클래스가 여러개
          
          의사결정트리(Decision Tree)
          로지스틱 회귀(Logistic Regression)
          K-최근접 이웃(K-Nearest Neighbors, KNN)
          나이브 베이즈(Naive Bayes)
          서포트 벡터 머신(Support Vector Machine, SVM)
          랜덤 포레스트(Random Forest)
          신경망(Neural Network)


    (2) 비지도학습(Unsupervised Learning) > prediction(label값)이 없음
    : 데이터는 있으나 맞춰야 할 값이 정해져 있지 않음. 
    스스로 그룹핑을 한다던지 다양한 방식을 수행한다.

        비지도학습의 종류 주요2가지

        - 군집화(Clustering)
          : 분류(지도학습)과 헷갈리지 말 것. > 뉴스를 하나하나 라벨링 할 수가 없으므로 스스로 알고리즘에 의해 분류함.
          grouping을 하는 것임.
           ex) 뉴스 분류(연예/정치/교육 등), 사용자 관심사(쇼핑, 여행, 게임 등)

           K-평균 클러스터링(K-Means Clustering)
          평균점 이동 클러스터링(Mean-Shift Clustering)
          DBSCAN(DensityBased Spatial Clustering of Applications with Noise)

        - 차원축소(Dimentionality Reduction)
          : 예측에 영향을 최대한 주지 않으면서 변수(Feature)를 축소하는 한다.
          고차원 데이터를 저차원의 데이터로 변환하는 비지도 학습

          주성분 분석(Principal Component Analysis, PCA)

    (3) 강화학습
    : 학습하는 시스템이 행동을 실행하고 그 결과에 따른 보상이나 벌점을 받는 방식으로 학습. 
    학습이 계속되면서 가장 큰 보상을 얻기 위한 최상의 전략을 스스로 학습하게 함.

4) 머신러닝 장점
    (1) 복잡한 패턴을 인지할 수 있음.
    (2) 적절한 알고리즘, 다양한 양질의 데이터가 있다면 좋은성능을 낼 수 있음.
    (3) 도메인 영역에 대한 지식이 상대적으로 부족해도 가능.

5) 머신러닝 문제점
    (1) 데이터 의존성이 큼. (Garbage in, Garbage out : 쓰레기를 넣으면 쓰레기가 나온다)
    (2) 과적합의 오류에 빠질 수 있음. (일반화의 오류, 데이터 다양성 요구) > 데이터의 편협성 문제
    (3) 풍부한 데이터가 기본적으로 요구됨.

6) 머신러닝 개발 절차

    1) Business Understanding
      : 머신러닝 개발을 통해 얻고자 하는 것 파악.

    2) Data Understanding
      - 데이터 수집
      - 탐색을 통해 데이터 파악

    3) Data Preprocessing
      : 데이터 전처리

    4) Modeling
      - 머신러닝 모델 선정
      - 모델 학습

    5) Evaluation
      - 모델 평가
      - 평가 결과에 따라 위 프로세스 반복
      
    6) Deployment
      : 평가 결과가 좋으면 실제 업무에 적용

7) 양질의 데이터는 무엇인가?
  좋은 성능을 내기 위해선 좋은데이터(quality(질)적 측면, quantity(양)적 측면)가 필요함.

  ex)
  전화번호를 수집함.   
  A는 010-xxxx-xxxx라고 입력. 
  B는 010xxxxxxxx로 입력. 
  C는 010 xxxx-xxxx라고 입력.

  이 때 사람이라면, 하이픈(-)이 있건 없건, 누락이 되었건 전화번호임을 구별 함.
  그러나 기계는 그렇지 못하기 때문에 데이터 가공, 즉 전처리(pre-processing)가 필요함.
  머신러닝 모델 자체가 일반화를 잘 할 수 있도록, 학습 전에 처리를 한 데이터가 필요함.

  데이터, 예측해야 할 값에 맞는 알고리즘을 사용해야 함.


